{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet donnée machine learning  \n",
    " #### Gabriel Rochon, Louis de Oliveira & Sofiya Ondriash \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = \"c:/Users/gabriel/Desktop/Dauphine/Dauphine L2/Semestre 2/MIDO/Intro machine learning réseaux de neurones/projet ml\"\n",
    "train_file_path = os.path.join(current_directory, 'X_train_G3tdtEn.csv')\n",
    "test_file_path = os.path.join(current_directory, 'Y_train_2_XPXJDyy.csv')\n",
    "\n",
    "# On charge les données\n",
    "df_train = pd.read_csv('X_train_G3tdtEn.csv')\n",
    "df_test = pd.read_csv('Y_train_2_XPXJDyy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opérations sur les colonnes et encodage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons défini une fonction `ajoutrapportprixquantite` qui ajoute une nouvelle colonne au DataFrame d'entraînement. Cette colonne, nommée `RapportPrixQuantite`, est calculée en divisant la somme des colonnes de prix par la somme des colonnes de quantités de produits achetés, afin d'analyser le rapport entre le prix total et la quantité totale de produits achetés pour chaque transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout colonne Rapport prix/quantité \n",
    "def ajoutrapportprixquantite(df_train):\n",
    "    prix = ['cash_price' + str(i+1) for i in range(24)]\n",
    "    qtt = ['Nbr_of_prod_purchas' + str(i+1) for i in range(24)]\n",
    "    df_train['RapportPrixQuantite'] = df_train[prix].sum(axis=1) / df_train[qtt].sum(axis=1)\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous avons défini une fonction `encoder` qui encode les colonnes catégorielles spécifiées. Nous avons généré les noms de colonnes pour les items, makes, et models, puis les combinons dans `cols_to_encode`. Ensuite, nous utilisons `pd.get_dummies` pour effectuer le one-hot encoding sur ces colonnes. Enfin, nous convertissons les valeurs booléennes en entiers pour garantir que toutes les colonnes encodées sont au format numérique pour préparer les données catégorielles pour les modèles que nous allons utiliser par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df_encoded):\n",
    "    items = ['item' + str(i+1) for i in range(24)]\n",
    "    makes = ['make' + str(i+1) for i in range(24)]\n",
    "    models = ['model' + str(i+1) for i in range(24)]\n",
    "    goods = ['goods_code' + str(i+1) for i in range(24)]\n",
    "    \n",
    "    cols_to_encode = items + makes + models\n",
    "\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=cols_to_encode)\n",
    "\n",
    "    # Convert boolean values to integers\n",
    "    for col in df_encoded.columns:\n",
    "        if col.split('_')[0] in items + models + makes: \n",
    "            df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajoutnombrecolonnesdansitems(df_test):\n",
    "    item_cols = ['item' + str(i+1) for i in range(24)]\n",
    "    df_test['nombre item'] = df_test[item_cols].count(axis=1)\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons défini trois fonctions pour améliorer la qualité de nos données: \n",
    "\n",
    "- La fonction `enlevergood_code` supprime les colonnes spécifiées des codes de produits dans le DataFrame encodé parce que nous voulions éliminer les colonnes inutiles ou redondantes avant de procéder à l'application des modèles aux données afin de réduire le nombre de colonnes à traiter pour le modèle.\n",
    "\n",
    "- La fonction `remplirde0` remplit les valeurs manquantes des colonnes de prix et de quantités par des zéros, garantissant ainsi que les analyses ultérieures ne soient pas faussées par des valeurs manquantes. \n",
    "\n",
    "- La fonction `filtrage` identifie et supprime les colonnes ayant un grand nombre de valeurs nulles (zéros), et crée des indicateurs de rareté pour les modèles, items, et marques. Cela réduit la dimensionnalité des données et met en avant les informations pertinentes, optimisant ainsi les performances des modèles de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la colloone 'goods_code' \n",
    "def enlevergood_code(df_encoded):\n",
    "    good = ['goods_code' + str(i) for i in range(1, 25)]\n",
    "    df_encoded = df_encoded.drop(good, axis=1)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplis de 0 les achats non effectué de manière optimisée\n",
    "\n",
    "def remplirde0_optimized(df_encoded):\n",
    "    cols = ['cash_price' + str(i+1) for i in range(24)]\n",
    "    qtt = ['Nbr_of_prod_purchas' + str(i+1) for i in range(24)]\n",
    "    df_encoded[cols + qtt] = df_encoded[cols + qtt].fillna(0)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtragemodif(df_encoded):\n",
    "    seuil=0.999*len(df_test)\n",
    "    cols_final=[]\n",
    "    col_a_supprimer = [col for col in df_encoded.columns if (df_encoded[col] == 0).sum() > seuil]\n",
    "    for i in range(1, 25):\n",
    "        model = 'model' + str(i)\n",
    "        item = 'item' + str(i)\n",
    "        mark = 'make' + str(i)   \n",
    "        peupresent = 'peupresent' +str(i)\n",
    "        cols_to_save_model= [col for col in col_a_supprimer if col.split('_')[0] in model]\n",
    "        df_encoded['peupresentmodel'+str(i)] = df_encoded[cols_to_save_model].sum(axis=1)\n",
    "        cols_final.extend(cols_to_save_model)\n",
    "        cols_to_save_item= [col for col in col_a_supprimer if col.split('_')[0] in item]\n",
    "        df_encoded['peupresentitem'+str(i)] = df_encoded[cols_to_save_item].sum(axis=1)\n",
    "        cols_final.extend(cols_to_save_item)\n",
    "        cols_to_save_mark= [col for col in col_a_supprimer if col.split('_')[0] in mark]\n",
    "        df_encoded['peupresentmark'+str(i)] = df_encoded[cols_to_save_mark].sum(axis=1)\n",
    "        cols_final.extend(cols_to_save_mark)\n",
    "        cols_to_save_peupresent= [col for col in col_a_supprimer if col.split('_')[0] in peupresent]\n",
    "        cols_final.extend(cols_to_save_peupresent)\n",
    "    df_encoded = df_encoded.drop(cols_final, axis=1)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous avons essayé une technique pour potentiellement fournir plus d'informations pertinentes au modèle pour affiner la précision.\n",
    "La fonction `ajoutecartalamoyenne` calcule l'écart par rapport à la moyenne pour chaque item. Elle crée une liste `item` avec les noms des colonnes d'items. Pour chaque colonne, si le nom de base n'est pas dans `item`, elle passe à la suivante. Sinon, elle calcule l'écart entre les valeurs de la colonne et la moyenne des valeurs non nulles, pondérées par le prix en espèces correspondant. Cet écart est normalisé et ajouté à une nouvelle colonne et les valeurs -1 sont remplacées par 0. Théoriquement, cette fonction pourrait aider à quantifier les écarts et d'identifier les anomalies par rapport à la moyenne pour chaque item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule l'écart à la moyenne de chaque catégorie de produit\n",
    "def calculate_ecart(group):\n",
    "    moyenne = group.mean()\n",
    "    ecart = (group - moyenne)/moyenne\n",
    "    return ecart\n",
    "\n",
    "# Ajout de la colonne ecart à la moyenne pour chaque item\n",
    "def ajout_ecart_a_la_moyenne_item(df_test):\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    for i in range(1, 25):\n",
    "        item_col = 'item' + str(i)\n",
    "        cash_col = 'cash_price' + str(i)\n",
    "        ecart_col = 'ecartitem' + str(i)\n",
    "        nb_col = 'Nbr_of_prod_purchas' + str(i)\n",
    "        df_test[ecart_col] = df_test.groupby(item_col)[cash_col].transform(calculate_ecart)\n",
    "        df_test[ecart_col] = df_test[ecart_col] * df_test[nb_col]\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    return df_test\n",
    "\n",
    "# Ajout de la colonne ecart à la moyenne pour chaque modèle\n",
    "def ajout_ecart_a_la_moyenne_modele(df_test):\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    for i in range(1, 25):\n",
    "        model = 'model' + str(i)\n",
    "        cash_col = 'cash_price' + str(i)\n",
    "        ecart_col = 'ecartmodel' + str(i)\n",
    "        nb_col = 'Nbr_of_prod_purchas' + str(i)\n",
    "        df_test[ecart_col] = df_test.groupby(model)[cash_col].transform(calculate_ecart)\n",
    "        df_test[ecart_col] = df_test[ecart_col] * df_test[nb_col]\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la colonne prixtotal\n",
    "def prixtotal(df_test):\n",
    "    cols = ['cash_price' + str(i) for i in range(1, 25)]\n",
    "    df_test['prixtotal'] = df_test[cols].sum(axis=1)\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    return df_test # ca marche\n",
    "\n",
    "# Ajout de la colonne qtt\n",
    "def qtt(df_test):\n",
    "    cols = ['Nbr_of_prod_purchas' + str(i) for i in range(1, 25)]\n",
    "    df_test['qtt'] = df_test[cols].sum(axis=1)\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    return df_test\n",
    "\n",
    "# Ajout de la colonne variation de prix\n",
    "def variationduprix(df_encoded):\n",
    "    for i in range(1, 24):\n",
    "        df_encoded['variation'+str(i)] = ((df_encoded['cash_price'+str(i+1)] * df_encoded['Nbr_of_prod_purchas'+str(i+1)])-(df_encoded['cash_price'+str(i)] * df_encoded['Nbr_of_prod_purchas'+str(i)]))\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def encodergoodcode (df_train):\n",
    "    encoder = OrdinalEncoder()\n",
    "    for i in range(1, 25):\n",
    "        df_train['goods_code'+str(i)] = df_train['goods_code'+str(i)].astype(str)\n",
    "        df_train['goods_code'+str(i)] = encoder.fit_transform(df_train['goods_code'+str(i)].values.reshape(-1, 1))\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `tout` applique une série de transformations et de filtrages sur le DataFrame df_test, composée de toutes les fonctions que nous avons détaillées auparavant afin de simplifier et centraliser le filtrage de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tout(df_test):\n",
    "    df_test = ajoutnombrecolonnesdansitems(df_test)\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    df_test = enlevergood_code(df_test)\n",
    "    df_test = prixtotal(df_test)\n",
    "    df_test = qtt(df_test)\n",
    "    df_test = variationduprix(df_test)\n",
    "    df_test = ajoutrapportprixquantite(df_test)\n",
    "    df_test = ajout_ecart_a_la_moyenne_item(df_test)\n",
    "    df_test = ajout_ecart_a_la_moyenne_modele(df_test)\n",
    "    df_test = encoder(df_test)\n",
    "    df_test = remplirde0_optimized (df_test)\n",
    "    df_test = filtragemodif(df_test)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded=tout(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On compare les colonnes après et avant l'encodage \n",
    "nb_colonne= df_encoded.shape[1]\n",
    "print(nb_colonne)\n",
    "print(df_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde si il a encore des colonnes avec des nan\n",
    "nan_columns = df_encoded.columns[df_encoded.isna().any()].tolist()\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=df_encoded['ID']\n",
    "X_train=df_encoded\n",
    "y_train=df_test['fraud_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programmes d'apprentissage et optimisation des programmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous avons importé la fonction `train_test_split` de sklearn.model_selection, puis divisé les données en ensembles d'entraînement et de validation avec une proportion de 80/20, en utilisant un état aléatoire pour la reproductibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_vraitrain et Y_vraitrain sont maintenant nos nouveaux ensembles d'entraînement\n",
    "# X_val et Y_val sont nos ensembles de validation\n",
    "X_vraitrain, X_val, y_vraitrain, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # On commence le chrono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On regarde si il y a des colonnes qui contiennent des valeurs infinies\n",
    "infinite_columns = df_encoded.columns[(df_encoded == np.inf).any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinite_columns # On affiche les colonnes qui contiennent des valeurs infinies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons ensuite la fonction `GridSearchCV`afin de trouver les meilleurs paramètres pour entraîner nos modèles. On utilise également GridSearch best estimator pour identifier le modèle optimal à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# On utilise GridSerchCV pour trouver les meilleurs hyperparamètres\n",
    "param_grid = {'n_estimators': [400],'max_depth': [20,25]}\n",
    "\n",
    "# On utilise 5-fold cross-validation et on parallèlise le processus \n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1, n_jobs=-1), param_grid, cv=5) \n",
    "grid_search.fit(X_vraitrain, y_vraitrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le meilleur modèle trouver par GridSearchCV\n",
    "model_RF = grid_search.best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params # On affiche les meilleurs parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.fit(X_vraitrain, y_vraitrain) # On entraine le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous avons exécuté plusieurs opérations pour transformer et vérifier la cohérence des ensembles de données d'entraînement et de validation. Ces opérations permettent de s'assurer que les ensembles de validation et d'entraînement ont les mêmes colonnes après transformation, en ajoutant des zéros là où des valeurs sont manquantes. Cela garantit que les modèles de machine learning reçoivent des données cohérentes, facilitant ainsi leur entraînement et leur évaluation. Les différences de colonnes sont également identifiées pour corriger les éventuelles incohérences entre les ensembles de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vraitrain.shape # On affiche la taille de notre ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.reindex(columns=X_vraitrain.columns) # On réindexe les colonnes de notre ensemble de validation\n",
    "X_val = X_val.fillna(0) # On remplace les valeurs manquantes par 0\n",
    "X_val.shape # On affiche la taille de notre ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les noms des colonnes en tant qu'ensembles\n",
    "columns_test = set(X_val.columns)\n",
    "columns_encoded = set(X_vraitrain.columns)\n",
    "\n",
    "# Trouver les colonnes qui sont dans df_test mais pas dans df_encoded\n",
    "diff_test_encoded = columns_test - columns_encoded\n",
    "print(\"Colonnes dans df_test mais pas dans df_encoded:\", diff_test_encoded)\n",
    "\n",
    "# Trouver les colonnes qui sont dans df_encoded mais pas dans df_test\n",
    "diff_encoded_test = columns_encoded - columns_test\n",
    "print(\"Colonnes dans df_encoded mais pas dans df_test:\", diff_encoded_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous avons évalué les performances du modèle model2 sur l'ensemble de validation X_val en utilisant la métrique d'AUC-PR (Area Under the Precision-Recall Curve) ainsi que la méthode `average precision score` de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_pred_proba = model_RF.predict_proba(X_val)[:, 1]\n",
    "y_pred = model_RF.predict(X_val)\n",
    "\n",
    "pr_auc = average_precision_score(y_val, y_pred)\n",
    "pr_auc2 = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f'PR-AUC: {pr_auc}')\n",
    "print(f'PR-AUC2: {pr_auc2}')\n",
    "\n",
    "end = time.time()\n",
    "print('Le temps est de ', end - start,'secondes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head() # On affiche les 5 premières lignes de notre ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous testons avec le modèle des K-plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start=time.time()\n",
    "nn = make_pipeline(preprocessing.StandardScaler(), KNeighborsClassifier())\n",
    "parameters = {'kneighborsclassifier__n_neighbors':[10]}\n",
    "clf = GridSearchCV(nn, parameters, verbose=1,n_jobs=-1)\n",
    "clf.fit(X_vraitrain, y_vraitrain)\n",
    "x=clf.best_params_\n",
    "print(x)\n",
    "y_pred = clf.predict_proba(X_val)[:, 1]\n",
    "pr_auc = average_precision_score(y_val, y_pred)\n",
    "print(f'PR-AUC: {pr_auc}')\n",
    "end=time.time()\n",
    "print('le temps est de ',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Régression logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous testons aussi le modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "start=time.time()\n",
    "nn = make_pipeline(preprocessing.StandardScaler(), LogisticRegression())\n",
    "parameters = {'logisticregression__C':np.linspace(1, 1000, 10)}\n",
    "clf2 = GridSearchCV(nn, parameters, verbose=1,n_jobs=-1)\n",
    "clf2.fit(X_vraitrain, y_vraitrain)\n",
    "end=time.time()\n",
    "x=clf2.best_params_\n",
    "print(x)\n",
    "z=clf2.best_score_\n",
    "print(z)\n",
    "y_pred = clf2.predict_proba(X_val)[:, 1]\n",
    "pr_auc = average_precision_score(y_val, y_pred)\n",
    "print(f'PR-AUC: {pr_auc}')\n",
    "temps=end-start\n",
    "print(\"le temps est de \",temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance des variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons également calculé et affiché la matrice de confusion pour les prédictions du modèle, ainsi que les taux de faux positifs (FP) et de faux négatifs (FN).\n",
    "Idéalement, un bon modèle de détection de fraude doit avoir un faible taux de faux négatifs, car il est crucial de détecter toutes les transactions frauduleuses possibles. Cependant, il est également important de maintenir un taux de faux positifs suffisamment bas pour éviter de perturber les transactions légitimes. L'équilibre entre ces deux taux dépend du coût associé aux faux positifs et aux faux négatifs, et on peut dire qu'ici la métrique plus importante est le faux négatif, car il faut correctement identifier le plus de transactions frauduleuses que possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau = pd.DataFrame()\n",
    "nouveau['fraud_flag'] = df_test['fraud_flag']\n",
    "nouveau['ID'] = df_test['ID']\n",
    "# Sorting the DataFrame by the 'fraud_flag' column\n",
    "print(nouveau.head())\n",
    "\n",
    "id = nouveau.loc[nouveau['fraud_flag'] == 1, 'ID'].tolist()\n",
    "id.sort()   \n",
    "dico={}\n",
    "somme=0\n",
    "s=0\n",
    "for i in range(1,len(id)):\n",
    "    for j in range(len(id)):\n",
    "        if id[j]+i in id:\n",
    "            somme+=1\n",
    "    dico[i]=somme\n",
    "    s+=somme\n",
    "    somme=0\n",
    "print(s)\n",
    "print('Dictionnaire du nombre de fraude en fonction de la distance entre elles')\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(list(dico.keys()), list(dico.values()))\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('Distance')\n",
    "ax.set_ylabel('Nombre de Fraudes')\n",
    "ax.set_title('Nombre de Fraudes en fonction de la distance entre elles')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary items into a list and take the first 10 items\n",
    "first_10_items = list(dico.items())[:10]\n",
    "\n",
    "# Convert the first 10 items back into a dictionary\n",
    "first_10_dict = dict(first_10_items)\n",
    "\n",
    "# Now you can plot the first 10 items\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(first_10_dict.keys()), list(first_10_dict.values()))\n",
    "ax.set_xlabel('Distance')\n",
    "ax.set_ylabel('Nombre de Fraudes')\n",
    "ax.set_title('Nombre de Fraudes en fonction de la distance entre elles')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# On calcule les importances des variables\n",
    "importances = model_RF.feature_importances_\n",
    "\n",
    "# Afficher les 5 variables les plus importantes\n",
    "indices = sorted(range(len(importances)), key=lambda k: importances[k], reverse=True)[20:]\n",
    "nom_colonnes = X_train.columns\n",
    "for i in indices[:5]:\n",
    "    print(f\"{nom_colonnes[i]} : {importances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_RF.feature_importances_\n",
    "\n",
    "# Afficher les 5 variables les plus importantes\n",
    "indices = sorted(range(len(importances)), key=lambda k: importances[k], reverse=True)[:20]\n",
    "nom_colonnes = X_train.columns\n",
    "for i in indices:\n",
    "    print(f\"{nom_colonnes[i]} : {importances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 10 variables les plus importantes\n",
    "nom_colonnes = X_train.columns\n",
    "\n",
    "# Créer un graphique à barres horizontal pour l'importance des variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(indices)),[importances[i] for i in indices],  align='center')\n",
    "plt.yticks(range(len(indices)),[nom_colonnes[i] for i in indices])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Top 20 Variables Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculez la matrice de confusion\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Calculez le taux de faux positifs et de faux négatifs\n",
    "fp_rate = cm[0, 1] / cm[0].sum()\n",
    "fn_rate = cm[1, 0] / cm[1].sum()\n",
    "\n",
    "print(f\"Taux de faux positif: {fp_rate}\")\n",
    "print(f\"Taux de faux négatif: {fn_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(y_val, y_pred) # On affiche le rapport de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un modele prudent qui dit plus facilement négatif que positif comme on dit vaut mieux 2 criminels dehors qu'un innocent en prison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RFF = model_RF\n",
    "model_RFF.fit(df_encoded , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la matrice de confusion\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrrice de confusion avec des classes plus équilibrées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Combinaison de sous-échantillonnage et de sur-échantillonnage\n",
    "tomek = TomekLinks(random_state=42)  # Réduit la majoritaire\n",
    "adasyn = ADASYN(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "X_vraitrain, y_vraitrain = adasyn.fit_resample(X_vraitrain, y_vraitrain)\n",
    "X_vraitrain, y_vraitrain = tomek.fit_resample(X_vraitrain, y_vraitrain)\n",
    "\n",
    "\n",
    "# Vérification des comptages de classe après sur-échantillonnage\n",
    "print(f\"Nombre d'échantillons par classe avant sur-échantillonnage : {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "print(f\"Nombre d'échantillons par classe après sur-échantillonnage : {dict(zip(*np.unique(y_vraitrain, return_counts=True)))}\")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=88, n_jobs=-1)\n",
    "model.fit(X_vraitrain, y_vraitrain)\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "pr_auc = average_precision_score(y_val, y_pred)\n",
    "print(f'PR-AUC: {pr_auc}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculez la matrice de confusion\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Calculez le taux de faux positifs et de faux négatifs\n",
    "fp_rate = cm[0, 1] / cm[0].sum()\n",
    "fn_rate = cm[1, 0] / cm[1].sum()\n",
    "\n",
    "print(f\"False positive rate: {fp_rate}\")\n",
    "print(f\"False negative rate: {fn_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soumission des données au site du challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = \"c:/Users/gabriel/Desktop/Dauphine/Dauphine L2/Semestre 2/MIDO/Intro machine learning réseaux de neurones/projet ml\"\n",
    "train_file_path = os.path.join(current_directory, 'X_test_8skS2ey.csv')\n",
    "\n",
    "# On accède au fichier test\n",
    "df_test = pd.read_csv(train_file_path)\n",
    "\n",
    "# On applique les mêmes transformations que sur le fichier train\n",
    "df_test = tout(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape # On affiche la taille de notre fichier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.shape # On affiche la taille de notre fichier train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie si les colonnes de df_test sont les mêmes que celles de df_encoded\n",
    "# On sauvegarde la colonne ID de df_test\n",
    "ID=df_test['ID']\n",
    "df_test=df_test\n",
    "df_test = df_test.reindex(columns=df_encoded.columns)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche la taille de notre fichier test\n",
    "df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les noms des colonnes en tant qu'ensembles\n",
    "columns_test = set(df_test.columns)\n",
    "columns_encoded = set(df_encoded.columns)\n",
    "\n",
    "# Trouver les colonnes qui sont dans df_test mais pas dans df_encoded\n",
    "diff_test_encoded = columns_test - columns_encoded\n",
    "print(\"Colonnes dans df_test mais pas dans df_encoded:\", diff_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les colonnes qui sont dans df_encoded mais pas dans df_test\n",
    "diff_encoded_test = columns_encoded - columns_test\n",
    "print(\"Colonnes dans df_encoded mais pas dans df_test:\", diff_encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prédit les probabilités de fraude et on enregistre les résultats dans un fichier csv\n",
    "X = model_RFF.predict_proba(df_test)[:, 1]\n",
    "n = df_test.shape[0]\n",
    "I = [i for i in range(n)]\n",
    "csv = pd.DataFrame({'index': I, 'ID': ID, 'fraud_flag': X})\n",
    "csv.to_csv(\"c:/Users/gabriel/Desktop/Dauphine/Dauphine L2/Semestre 2/MIDO/Intro machine learning réseaux de neurones/projet ml/submission10\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche la taille de notre ensemble de prédcition\n",
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche le type de X\n",
    "type(X) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
